# DetecciÃ³n de Centros Ã“pticos en Patrones de Referencia MÃ³viles Aplicados

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg)](https://opencv.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Experimental-orange.svg)](README.md)

> **Sistema de detecciÃ³n y tracking de marcadores Ã³pticos LED para aplicaciones de Helmet Mounted Display (HMD)**

Sistema **en desarrollo activo** para la detecciÃ³n automÃ¡tica de marcadores LED infrarojos y el cÃ¡lculo preciso de sus centros Ã³pticos, diseÃ±ado para sistemas de trackeo de cascos en tiempo real en aeronaves.

---

## âš ï¸ ADVERTENCIA IMPORTANTE

**Este proyecto se encuentra en fase experimental y NO estÃ¡ listo para uso en producciÃ³n.**

### Limitaciones CrÃ­ticas Actuales:

- ğŸ”´ **Alta tasa de falsos positivos** - El sistema confunde objetos brillantes con LEDs reales
- ğŸ”´ **Error de precisiÃ³n elevado** - Desviaciones de hasta 122 pÃ­xeles (inaceptable para trackeo de precisiÃ³n)
- ğŸ”´ **Sin validaciÃ³n ground-truth** - Los resultados reportados no han sido verificados contra posiciones reales conocidas
- ğŸ”´ **MÃ©todo de parpadeo NO implementado** - TÃ©cnica crÃ­tica para eliminar ruido IR pendiente
- ğŸ”´ **Sin filtro predictivo (Kalman)** - Tracking temporal bÃ¡sico, vulnerable a oclusiones
- ğŸ”´ **Sin correcciÃ³n de distorsiÃ³n** - No considera aberraciones de lente

**Los datos estadÃ­sticos presentados incluyen detecciones errÃ³neas y NO deben considerarse confiables para evaluaciÃ³n cuantitativa.**

### PrÃ³ximos Pasos CrÃ­ticos:
1. Implementar mÃ©todo de detecciÃ³n por parpadeo sincronizado
2. Establecer ground-truth y validar resultados
3. Calibrar cÃ¡mara y corregir distorsiÃ³n
4. Implementar filtro de Kalman
5. Reducir error a Ïƒ < 5 px por LED

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [MetodologÃ­a](#-metodologÃ­a)
- [CaracterÃ­sticas Principales](#-caracterÃ­sticas-principales)
- [Resultados Actuales](#-resultados-actuales)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n y Uso](#-instalaciÃ³n-y-uso)
- [DocumentaciÃ³n](#-documentaciÃ³n)
- [Estado del Proyecto](#-estado-del-proyecto)
- [Autor](#-autor)

---

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto desarrolla un sistema de visiÃ³n por computadora para la **detecciÃ³n robusta de marcadores LED infrarojos** y el **cÃ¡lculo de sus centros Ã³pticos con precisiÃ³n subpÃ­xel**, aplicado al trackeo de Helmet Mounted Displays (HMD) en entornos aeronÃ¡uticos.

### Contexto y AplicaciÃ³n

Los sistemas HMD modernos requieren conocer con alta precisiÃ³n la posiciÃ³n y orientaciÃ³n de la cabeza del piloto en tiempo real. Para lograrlo, se utilizan marcadores Ã³pticos LED (infrarojos) montados en el casco o en la cabina, cuyas posiciones son detectadas por cÃ¡maras. La precisiÃ³n en la determinaciÃ³n de los **centros Ã³pticos** de estos marcadores es crÃ­tica para el correcto funcionamiento del sistema de realidad aumentada.

### Objetivos del Proyecto

1. **Desarrollar algoritmos robustos** para la detecciÃ³n de marcadores LED en condiciones variables de iluminaciÃ³n
2. **Calcular centros Ã³pticos con precisiÃ³n subpÃ­xel** minimizando errores de estimaciÃ³n
3. **Operar en tiempo real** (compatible con video streaming a 24+ fps)
4. **Minimizar falsos positivos y negativos** mediante tÃ©cnicas multi-mÃ©todo
5. **Cuantificar el error inherente** en la estimaciÃ³n de centros Ã³pticos bajo diversas condiciones

---

## ğŸ”¬ MetodologÃ­a

El proyecto se estructura en **tres etapas** segÃºn el plan metodolÃ³gico establecido:

### **Etapa 1: AnÃ¡lisis y Desarrollo de Algoritmos** ğŸ”„ *En Desarrollo*

AnÃ¡lisis de herramientas de procesamiento de imÃ¡genes y desarrollo de software para detecciÃ³n de marcadores con mÃ­nima tasa de falsos positivos/negativos y determinaciÃ³n precisa de centros Ã³pticos.

**Estado actual:** Se han implementado tÃ©cnicas preliminares, pero **el sistema NO cumple aÃºn con los objetivos de precisiÃ³n y robustez** establecidos. Se requiere trabajo adicional significativo.

**TÃ©cnicas implementadas (estado experimental):**

| TÃ©cnica | PropÃ³sito | Estado |
|---------|-----------|--------|
| **ConversiÃ³n a escala de grises** | SimplificaciÃ³n del anÃ¡lisis (cÃ¡maras RGB con seÃ±al IR) | âœ… Implementado |
| **Espacio de color HSV** | SegmentaciÃ³n de regiones brillantes y saturadas | âš ï¸ Implementado, requiere calibraciÃ³n |
| **Filtrado espacial (Gaussiano, mediana)** | ReducciÃ³n de ruido sin pÃ©rdida de estructura | âœ… Implementado |
| **UmbralizaciÃ³n adaptativa** | Aislamiento de regiones intensas con iluminaciÃ³n no uniforme | âš ï¸ Implementado, parÃ¡metros no Ã³ptimos |
| **DetecciÃ³n de blobs brillantes** | LocalizaciÃ³n de agrupaciones de pÃ­xeles compatibles con LEDs | âš ï¸ Implementado, genera falsos positivos |
| **DetecciÃ³n de bordes (Canny)** | Resaltado de contornos definidos | âœ… Implementado |
| **Transformada de Hough (cÃ­rculos)** | DetecciÃ³n de estructuras circulares/elÃ­pticas | âš ï¸ Implementado, insuficientemente restrictivo |
| **Filtro contextual (validaciÃ³n de vecindad)** | VerificaciÃ³n geomÃ©trica e intensidad en torno al LED | âš ï¸ Parcial, requiere mejora |
| **CÃ¡lculo del centro geomÃ©trico** | PrecisiÃ³n subpÃ­xel mediante centroide ponderado | âš ï¸ Implementado, alta variabilidad |
| **Tracking temporal** | IdentificaciÃ³n consistente de LEDs entre fotogramas | âš ï¸ BÃ¡sico, necesita filtro predictivo |
| **Filtrado estadÃ­stico (IQR)** | EliminaciÃ³n automÃ¡tica de outliers | âš ï¸ Insuficiente |
| **DetecciÃ³n de parpadeo sincronizado** | **CRÃTICO**: Aumentar contraste frente al fondo restando frames LED on/off | ğŸ”´ **NO IMPLEMENTADO** |
| **CorrecciÃ³n de perspectiva** | Ajuste geomÃ©trico por Ã¡ngulo de cÃ¡mara | ğŸ”´ **NO IMPLEMENTADO** |
| **Tracking predictivo (Kalman)** | Robustez temporal ante oclusiones | ğŸ”´ **NO IMPLEMENTADO** |

**Estrategia multi-mÃ©todo:** El sistema combina **4 mÃ©todos de detecciÃ³n paralelos** cuyos resultados se fusionan mediante clustering espacial. Sin embargo, **esta estrategia es insuficiente** sin la implementaciÃ³n del mÃ©todo de parpadeo y validaciÃ³n contextual mÃ¡s estricta.

### **Etapa 2: DiseÃ±o de Ensayos de ValidaciÃ³n** ğŸ”„ *En planificaciÃ³n*

DefiniciÃ³n del conjunto de ensayos para estimar el error en la determinaciÃ³n de coordenadas de centros Ã³pticos bajo diferentes condiciones ambientales.

**Factores a evaluar:**
- VariaciÃ³n de iluminaciÃ³n ambiental
- Distancia cÃ¡mara-marcadores
- Ãngulo de observaciÃ³n
- Velocidad de movimiento del patrÃ³n
- Interferencias (reflejos, obstrucciones parciales)

### **Etapa 3: Ensayo y AnÃ¡lisis Comparativo** â³ *Pendiente*

Ensayo de los algoritmos desarrollados con el conjunto de pruebas diseÃ±ado, anÃ¡lisis estadÃ­stico de resultados y determinaciÃ³n del algoritmo Ã³ptimo.

---

## âœ¨ CaracterÃ­sticas Principales

### Sistema de DetecciÃ³n Multi-MÃ©todo (Experimental)

El detector combina 4 algoritmos complementarios en su versiÃ³n actual:

1. **UmbralizaciÃ³n de alta intensidad** - DetecciÃ³n directa de pÃ­xeles muy brillantes (genera falsos positivos)
2. **SimpleBlobDetector** - AnÃ¡lisis geomÃ©trico de regiones candidatas (criterios demasiado permisivos)
3. **Transformada de Hough para cÃ­rculos** - ValidaciÃ³n de geometrÃ­a circular (insuficientemente restrictiva)
4. **SegmentaciÃ³n HSV** - Aislamiento por brillo y saturaciÃ³n (requiere calibraciÃ³n)

âš ï¸ **LimitaciÃ³n actual:** Sin el mÃ©todo de parpadeo sincronizado, estos algoritmos generan numerosos falsos positivos al confundir LEDs con otros objetos brillantes (reflejos, artefactos, ruido IR).

### Tracking Temporal BÃ¡sico

- **IdentificaciÃ³n por proximidad** entre fotogramas consecutivos
- **Memoria espacial limitada** - Predice posiciÃ³n basÃ¡ndose solo en frame anterior
- âš ï¸ **Sin filtro predictivo robusto** (Kalman) - Vulnerable a oclusiones y movimientos bruscos
- âš ï¸ **PÃ©rdida de identidad** en casos de cruce de LEDs o detecciones ambiguas

### Procesamiento en Tiempo Real

- **Velocidad:** ~24 fps en hardware estÃ¡ndar
- **ConfiguraciÃ³n parametrizable** vÃ­a cÃ³digo (no archivo de configuraciÃ³n externo)
- **MÃºltiples modos de salida:** video anotado, JSON, reportes estadÃ­sticos
- âš ï¸ **Advertencia:** Velocidad no garantiza precisiÃ³n - muchas detecciones son errÃ³neas

### AnÃ¡lisis EstadÃ­stico AutomÃ¡tico

- CÃ¡lculo de **desviaciÃ³n estÃ¡ndar** por LED y por eje
- DetecciÃ³n automÃ¡tica de **outliers** (mÃ©todo IQR - insuficiente)
- GeneraciÃ³n de **reportes detallados** con mÃ©tricas
- âš ï¸ **Problema crÃ­tico:** Las estadÃ­sticas incluyen falsos positivos sin filtrar, por lo que **no son confiables** para evaluaciÃ³n cuantitativa real

---

## ğŸ“Š Resultados Actuales

### **Etapa 1: DetecciÃ³n en Video de Prueba - Estado Experimental**

**Condiciones del Experimento:**

El experimento se realizÃ³ bajo las siguientes condiciones de laboratorio:

- **PatrÃ³n de prueba:** 3 LEDs infrarrojos montados en soporte mÃ³vil
- **CÃ¡mara:** TelÃ©fono mÃ³vil estÃ¡ndar (no especializada en captura IR)
- **Entorno:** Laboratorio con iluminaciÃ³n natural variable
  - Presencia de luz solar indirecta
  - Reflejos sobre superficies del laboratorio
  - Condiciones de iluminaciÃ³n NO controladas
- **Video capturado:** `patron_leds.mp4` (1280Ã—720 px, 24 fps, 854 frames, ~35 segundos)
- **Movimiento:** PatrÃ³n LED en movimiento manual continuo

âš ï¸ **Limitaciones del setup experimental:**
- CÃ¡mara de telÃ©fono NO optimizada para captura de luz infrarroja
- Presencia de ruido IR ambiental y reflejos de luz solar
- IluminaciÃ³n variable durante la captura
- Sin control de distancia ni Ã¡ngulo de observaciÃ³n
- Sin marcadores ground-truth para validaciÃ³n de posiciones reales

Estas condiciones no controladas **aumentan significativamente la dificultad** de detecciÃ³n precisa y explican en parte la alta tasa de falsos positivos observada.

---

#### âš ï¸ Estado Actual: **EXPERIMENTAL - REQUIERE VALIDACIÃ“N**

Si bien el sistema procesa los 854 fotogramas y genera detecciones, **los resultados NO estÃ¡n validados** y presentan **limitaciones crÃ­ticas**:

- âš ï¸ **Alta tasa de falsos positivos**: Muchas detecciones reportadas no corresponden a los centros Ã³pticos reales
- âš ï¸ **Error elevado**: Desviaciones de hasta 122 px (LED 3) son **inaceptables** para aplicaciones de trackeo de precisiÃ³n
- âš ï¸ **Falta de validaciÃ³n ground-truth**: No se han comparado las detecciones con posiciones reales conocidas
- âš ï¸ **EstadÃ­sticas no confiables**: Los datos reportados incluyen detecciones errÃ³neas sin filtrado adecuado

#### Datos Preliminares (NO VALIDADOS)

| LED | PosiciÃ³n Promedio (x, y) | DesviaciÃ³n Ïƒ | ObservaciÃ³n |
|-----|-------------------------|--------------|-------------|
| **LED 1** | (344.71, 394.74) px | **54.68 px** | Error moderado-alto, requiere mejora |
| **LED 2** | (874.13, 360.16) px | **32.23 px** | Menor desviaciÃ³n, aÃºn insuficiente |
| **LED 3** | (1151.53, 601.75) px | **98.07 px** | **Error crÃ­tico**, inaceptable para uso real |

![Ejemplo de detecciÃ³n](estimacion_centros_opticos/Informes/Informe1/image-1.png)

#### âš ï¸ Problemas Identificados

**Errores de precisiÃ³n:**

| LED | Ïƒ_x (px) | Ïƒ_y (px) | Problema Principal |
|-----|----------|----------|-------------------|
| LED 1 | 71.10 | 50.38 | ConfusiÃ³n con reflejos/ruido, desviaciÃ³n excesiva |
| LED 2 | 44.40 | 25.56 | Menor error pero aÃºn por encima del umbral aceptable |
| LED 3 | 122.11 | 96.52 | **Error crÃ­tico**: probable confusiÃ³n sistemÃ¡tica con otros objetos brillantes |

**Principales limitaciones detectadas:**
1. **Falsos positivos frecuentes**: El sistema detecta objetos brillantes que no son LEDs (reflejos, artefactos)
2. **Falta de discriminaciÃ³n contextual**: No valida suficientemente el entorno del LED (anillo negro, geometrÃ­a esperada)
3. **Ausencia de validaciÃ³n temporal robusta**: No aprovecha la coherencia temporal para filtrar detecciones espurias
4. **Sin correcciÃ³n de distorsiÃ³n**: No considera distorsiÃ³n de lente ni perspectiva
5. **UmbralizaciÃ³n inadecuada**: Los parÃ¡metros actuales no son suficientemente selectivos

#### TÃ©cnicas Implementadas (Requieren Mejora)

- âš ï¸ **UmbralizaciÃ³n adaptativa** - Implementada pero con parÃ¡metros no optimizados
- âš ï¸ **DetecciÃ³n geomÃ©trica de blobs** - Criterios demasiado permisivos, genera falsos positivos
- âš ï¸ **Transformada de Hough** - No suficientemente restrictiva
- âš ï¸ **SegmentaciÃ³n HSV** - Requiere calibraciÃ³n
- âš ï¸ **Tracking temporal** - BÃ¡sico, necesita filtro predictivo (Kalman)
- âš ï¸ **Filtrado IQR** - Insuficiente para eliminar todos los outliers

![Pipeline de procesamiento](estimacion_centros_opticos/Informes/Informe1/image-2.png)

---

## ğŸ“ Estructura del Proyecto

```
Estimacion-Pose-Casco/
â”‚
â”œâ”€â”€ README.md                          # Este archivo
â”‚
â””â”€â”€ estimacion_centros_opticos/        # MÃ³dulo principal
    â”‚
    â”œâ”€â”€ led_detector_final.py          # â­ Detector final (4 mÃ©todos combinados)
    â”œâ”€â”€ led_detector_video_output.py   # Procesador con salida de video anotado
    â”œâ”€â”€ diagnostic.py                  # Herramienta de diagnÃ³stico de video
    â”‚
    â”œâ”€â”€ run.sh                         # Script de ejecuciÃ³n principal
    â”œâ”€â”€ run_live.sh                    # Script para ejecuciÃ³n en tiempo real
    â”œâ”€â”€ generate_marked_video.sh       # Generador de video con marcas
    â”‚
    â”œâ”€â”€ .gitignore                     # Exclusiones de Git
    â”œâ”€â”€ .pylintrc                      # ConfiguraciÃ³n de linting
    â”œâ”€â”€ README.md                      # DocumentaciÃ³n del mÃ³dulo
    â”‚
    â”œâ”€â”€ documentacion_codigo/          # ğŸ“š DocumentaciÃ³n tÃ©cnica completa
    â”‚   â”œâ”€â”€ DOCUMENTACION_CODIGO.md    # DocumentaciÃ³n detallada del cÃ³digo
    â”‚   â”œâ”€â”€ GUIA_RAPIDA.md             # GuÃ­a de inicio rÃ¡pido
    â”‚   â”œâ”€â”€ INICIO_RAPIDO.md           # Tutorial de primeros pasos
    â”‚   â”œâ”€â”€ SINTAXIS_PYTHON.md         # Referencia de sintaxis
    â”‚   â”œâ”€â”€ MAPA_MENTAL.md             # Mapa conceptual del proyecto
    â”‚   â”œâ”€â”€ INDICE.md                  # Ãndice navegable
    â”‚   â””â”€â”€ INDICE_DOCUMENTACION.md    # Ãndice de documentaciÃ³n
    â”‚
    â”œâ”€â”€ analisis_metodos_utilizados/   # ğŸ” AnÃ¡lisis metodolÃ³gico
    â”‚   â”œâ”€â”€ 1. DIAGRAMA_VISUAL_METODOS.md
    â”‚   â”œâ”€â”€ 2. ANALISIS_METODOS_IMPLEMENTADOS.md
    â”‚   â”œâ”€â”€ 3. CONCLUSIONES_METODOS.md
    â”‚   â”œâ”€â”€ 4. REFERENCIA_TECNICA_METODOS.md
    â”‚   â”œâ”€â”€ 5. MAPEO_LINEAS_CODIGOS.md
    â”‚   â””â”€â”€ 6. MAPA_NAVEGACION_COMPLETO.md
    â”‚
    â”œâ”€â”€ Informes/                      # ğŸ“„ Informes del proyecto
    â”‚   â””â”€â”€ Informe1/
    â”‚       â”œâ”€â”€ INFORME_NARRATIVO_ETAPA_1.md  # Informe detallado Etapa 1
    â”‚       â”œâ”€â”€ INFORME_FUNES_TOBIAS.pdf      # Informe formal
    â”‚       â””â”€â”€ *.png                          # ImÃ¡genes del informe
    â”‚
    â”œâ”€â”€ patron_leds/                   # ğŸ¥ Videos de prueba
    â”‚   â”œâ”€â”€ patron_leds.mp4            # Video principal de prueba
    â”‚   â””â”€â”€ video_prueba.mp4           # Video alternativo
    â”‚
    â”œâ”€â”€ resultados_v1/                 # ğŸ“Š Resultados versiÃ³n 1
    â”‚   â”œâ”€â”€ RESULTADOS_FINALES.md      # Resumen de resultados
    â”‚   â”œâ”€â”€ reporte_deteccion.txt      # Reporte textual detallado
    â”‚   â”œâ”€â”€ resultados_completos.json  # Base de datos frame-by-frame
    â”‚   â”œâ”€â”€ resumen_estadisticas.json  # EstadÃ­sticas agregadas
    â”‚   â””â”€â”€ frames/                    # Fotogramas procesados con marcas
    â”‚
    â””â”€â”€ versiones_anteriores_descartadas/  # ğŸ—ƒï¸ Versiones de desarrollo
        â”œâ”€â”€ led_detector_v1.py
        â”œâ”€â”€ led_detector_v2.py
        â”œâ”€â”€ led_detector_mejorado.py
        â”œâ”€â”€ led_detector_calibrado.py
        â”œâ”€â”€ led_detector_stable.py
        â””â”€â”€ README_led_detector_v1_y_v2.md
```

---

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos Previos

- **Python 3.10+**
- **OpenCV 4.x** (`opencv-python`)
- **NumPy**
- Sistema operativo: Linux, macOS, Windows

### InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/TOB1EH/Proyecto-Deteccion-de-centros-opticos-en-patrones-de-referencia-moviles-aplicados.git
cd Proyecto-Deteccion-de-centros-opticos-en-patrones-de-referencia-moviles-aplicados/estimacion_centros_opticos

# 2. Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# 3. Instalar dependencias
pip install opencv-python numpy
```

### Uso BÃ¡sico

#### Procesamiento de Video con Salida Anotada

```bash
# Ejecutar detector sobre video de prueba
./run.sh

# O manualmente:
python led_detector_video_output.py patron_leds/patron_leds.mp4 resultados/
```

**Salidas generadas:**
- `resultados/frames/`: Fotogramas con LEDs marcados en color
- `resultados/resultados_completos.json`: Datos frame-by-frame
- `resultados/resumen_estadisticas.json`: EstadÃ­sticas agregadas
- `resultados/reporte_deteccion.txt`: Informe textual

#### DiagnÃ³stico de Video

```bash
# Analizar propiedades del video
python diagnostic.py patron_leds/patron_leds.mp4
```

#### GeneraciÃ³n de Video Marcado

```bash
# Crear video con LEDs marcados visualmente
./generate_marked_video.sh
```

### ConfiguraciÃ³n Avanzada

El detector es altamente parametrizable. Consulta `documentacion_codigo/GUIA_RAPIDA.md` para opciones de configuraciÃ³n.

---

## ğŸ“š DocumentaciÃ³n

La documentaciÃ³n completa del proyecto se encuentra organizada en:

### DocumentaciÃ³n TÃ©cnica
- **[DOCUMENTACION_CODIGO.md](estimacion_centros_opticos/documentacion_codigo/DOCUMENTACION_CODIGO.md)** - ExplicaciÃ³n detallada de cada mÃ³dulo y funciÃ³n
- **[GUIA_RAPIDA.md](estimacion_centros_opticos/documentacion_codigo/GUIA_RAPIDA.md)** - Referencia rÃ¡pida de uso
- **[INICIO_RAPIDO.md](estimacion_centros_opticos/documentacion_codigo/INICIO_RAPIDO.md)** - Tutorial para comenzar

### AnÃ¡lisis MetodolÃ³gico
- **[ANALISIS_METODOS_IMPLEMENTADOS.md](estimacion_centros_opticos/analisis_metodos_utilizados/2.%20ANALISIS_METODOS_IMPLEMENTADOS.md)** - EvaluaciÃ³n de tÃ©cnicas aplicadas
- **[CONCLUSIONES_METODOS.md](estimacion_centros_opticos/analisis_metodos_utilizados/3.%20CONCLUSIONES_METODOS.md)** - Conclusiones y recomendaciones

### Informes de Etapa
- **[INFORME_NARRATIVO_ETAPA_1.md](estimacion_centros_opticos/Informes/Informe1/INFORME_NARRATIVO_ETAPA_1.md)** - Informe completo de la Etapa 1

---

## ğŸ”§ Estado del Proyecto

### âš ï¸ Estado General: **EN DESARROLLO ACTIVO - NO LISTO PARA PRODUCCIÃ“N**

El proyecto se encuentra en fase experimental. Si bien se han implementado mÃºltiples tÃ©cnicas de detecciÃ³n, **el sistema NO es confiable** para aplicaciones reales debido a falsos positivos y errores de precisiÃ³n significativos.

### âœ… Completado (Fase Experimental)

- [x] **Etapa 1 (Parcial):** ImplementaciÃ³n inicial de algoritmo multi-mÃ©todo
- [x] ImplementaciÃ³n de 4 tÃ©cnicas de detecciÃ³n (requieren refinamiento)
- [x] Sistema de tracking temporal bÃ¡sico
- [x] GeneraciÃ³n automÃ¡tica de reportes estadÃ­sticos
- [x] Procesamiento en tiempo real (~24 fps)
- [x] DocumentaciÃ³n tÃ©cnica del cÃ³digo base
- [x] Pruebas preliminares en video de laboratorio

### ğŸ”´ Problemas CrÃ­ticos Identificados

- [ ] **Alta tasa de falsos positivos** - El sistema detecta objetos que no son LEDs
- [ ] **Error de precisiÃ³n inaceptable** - Desviaciones de hasta 122 px (LED 3)
- [ ] **Falta de validaciÃ³n ground-truth** - No hay comparaciÃ³n con posiciones reales conocidas
- [ ] **ParÃ¡metros no optimizados** - Umbrales y criterios geomÃ©tricos demasiado permisivos
- [ ] **Ausencia de correcciÃ³n de distorsiÃ³n** - No se consideran aberraciones de lente
- [ ] **Tracking temporal insuficiente** - Falta filtro predictivo robusto (Kalman)

### ğŸ”„ Trabajo Pendiente CrÃ­tico (Etapa 1)

- [ ] **Implementar mÃ©todo de parpadeo sincronizado** - Crucial para eliminar falsos positivos
  - Capturar frames con LED encendido/apagado
  - Restar frames para aislar LEDs reales
  - Aumentar contraste LED vs. ruido IR
- [ ] **ValidaciÃ³n con ground-truth** - Establecer posiciones reales conocidas
- [ ] **CalibraciÃ³n de cÃ¡mara** - Matriz intrÃ­nseca y correcciÃ³n de distorsiÃ³n
- [ ] **Filtro de Kalman** - PredicciÃ³n temporal de posiciones
- [ ] **Refinamiento de parÃ¡metros** - Ajuste basado en validaciÃ³n cuantitativa
- [ ] **Mejora de filtro contextual** - Validar anillo negro/fondo oscuro estricto
- [ ] **DetecciÃ³n de oclusiones** - Manejo robusto de LEDs parcialmente ocultos
- [ ] **ReducciÃ³n de error** - Objetivo: Ïƒ < 5 px por LED

### ğŸ”„ Etapa 2: DiseÃ±o de Ensayos (No Iniciada)

- [ ] Definir protocolo de validaciÃ³n con ground-truth
- [ ] DiseÃ±ar ensayos bajo condiciones variables:
  - [ ] IluminaciÃ³n ambiental (controlada, natural, variable)
  - [ ] Distancia cÃ¡mara-marcadores (rango operativo)
  - [ ] Ãngulo de observaciÃ³n (frontal, lateral, extremo)
  - [ ] Velocidad de movimiento (estÃ¡tico, lento, rÃ¡pido)
  - [ ] Interferencias (reflejos, obstrucciones, ruido IR)
- [ ] Establecer mÃ©tricas de calidad aceptables
- [ ] Crear conjunto de videos de prueba controlados

### â³ Etapa 3: Ensayo y AnÃ¡lisis (No Iniciada)

- [ ] Ensayo comparativo de algoritmos mejorados
- [ ] AnÃ¡lisis estadÃ­stico exhaustivo con datos validados
- [ ] CaracterizaciÃ³n cuantitativa del error
- [ ] ComparaciÃ³n con literatura/sistemas comerciales
- [ ] DocumentaciÃ³n de limitaciones y condiciones de uso
- [ ] Informe final con recomendaciones

### ğŸ¯ Mejoras Planificadas (Prioridad Alta)

1. **DetecciÃ³n por parpadeo** - Esencial para eliminar ruido
2. **CalibraciÃ³n de cÃ¡mara** - CorrecciÃ³n de distorsiÃ³n geomÃ©trica
3. **Filtro de Kalman** - PredicciÃ³n temporal robusta
4. **ValidaciÃ³n ground-truth** - Establecer precisiÃ³n real del sistema
5. **Ajuste de parÃ¡metros** - OptimizaciÃ³n basada en datos validados
6. **Manejo de oclusiones** - RecuperaciÃ³n tras pÃ©rdida temporal
7. **CorrecciÃ³n de perspectiva 3D** - TransformaciÃ³n a coordenadas mundo
8. **IntegraciÃ³n PnP** - EstimaciÃ³n de pose 6-DOF del casco

---

## ğŸ‘¨â€ğŸ’» Autor

**Tobias Funes**  
Facultad de IngenierÃ­a - Instituto Universitario AeronÃ¡utico (IUA)  
Proyecto: Sistema de Trackeo para HMD (Helmet Mounted Display)  
PerÃ­odo: Octubre-Noviembre 2025

---

## ğŸ™ Agradecimientos

- OpenCV Community por las herramientas de visiÃ³n por computadora
- IUA - Facultad de IngenierÃ­a por el soporte acadÃ©mico
- Proyecto de investigaciÃ³n en sistemas HMD para aviaciÃ³n

---

**ğŸ”— Enlaces Ãštiles:**
- [Repositorio GitHub](https://github.com/TOB1EH/Proyecto-Deteccion-de-centros-opticos-en-patrones-de-referencia-moviles-aplicados)
- [DocumentaciÃ³n OpenCV](https://docs.opencv.org/)
- [Issues y Sugerencias](https://github.com/TOB1EH/Proyecto-Deteccion-de-centros-opticos-en-patrones-de-referencia-moviles-aplicados/issues)
